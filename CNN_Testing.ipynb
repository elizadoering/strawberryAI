{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFjmOBSC1AtH"
   },
   "source": [
    "Adding library imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "vhgsbq11oXGm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16rb6AES0_Vs"
   },
   "source": [
    "Reading the initial strawberry files. Matplotlib's default color scheme BGR, so the initial reading\n",
    "(as shown here) is reading the jpg color code's in reverse order. The image should be displayed as follows, but the output is incorrect.   \n",
    "\n",
    "![r_130_100.jpg](data:image/jpeg;base64,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)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qulK-gu5Bdg"
   },
   "source": [
    "Here the image is updated to the color colorscheme using cvtColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "WYK02wDx2wx9",
    "outputId": "fbd58b39-559e-437c-a4d5-451344b7535a"
   },
   "outputs": [],
   "source": [
    "# displaying images with updated RBG color scheme \n",
    "#colorFixImg = cv2.cvtColor(images[0], cv2.COLOR_BGR2RGB)\n",
    "#plt.imshow(colorFixImg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "SbevQGoKBApA",
    "outputId": "d6649ff0-62ab-43ff-f448-91967b27e9ec"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "path = \"/Users/Bobby/Fall2020/Artificial Intelligence/Semester Project/fruits-360/Training/*/*\"\n",
    "files = []\n",
    "[files.extend(glob.glob(path + '*.jpg'))]\n",
    "\n",
    "# shuffle pitcures\n",
    "random.shuffle(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "6pLaSn5BPAOK",
    "outputId": "0d515976-bb36-46d6-82d9-1c2827d01c67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of files: 2677\n",
      "Number of Strawberry Images: 946\n",
      "Number of Images: 2677\n",
      "Shape of Images: (2677, 100, 100, 3)\n",
      "Shape of Labels: (2677, 1)\n"
     ]
    }
   ],
   "source": [
    "# label the strawberry images\n",
    "IMG_SIZE = 100\n",
    "labels = []\n",
    "images = []\n",
    "strawCount = 0\n",
    "image_count = 0\n",
    "print('Length of files:', len(files))\n",
    "for file in files:\n",
    "    if 'Strawberry' in file or 'strawberry' in file:\n",
    "        labels.append(1)\n",
    "        strawCount += 1\n",
    "    else: labels.append(0)    \n",
    "    image = cv2.imread(os.path.join(path, file))\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_AREA)\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "labels.resize(len(labels), 1)\n",
    "print('Number of Strawberry Images:', strawCount)\n",
    "print('Number of Images:', len(images))\n",
    "print('Shape of Images:', images.shape)\n",
    "print('Shape of Labels:', labels.shape)\n",
    "#plt.imshow(images[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom skimage.util import img_as_float\\nnew_Images = []\\ndim =100\\nfor i in range(0,len(images2)):\\n   # m_rgb = cv2.cvtColor(images2[i], cv2.COLOR_BGR2RGB)\\n    image = np.asarray(images2[i],dtype=object)\\n    new_Images.append((image,labels[i]))\\ndf = pd.DataFrame(new_Images, columns=['Image','Label'])\\nX = np.array(df['Image'])\\ny = np.array(df['Label'])\\ndf.head()\\n\""
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe\n",
    "'''\n",
    "from skimage.util import img_as_float\n",
    "new_Images = []\n",
    "dim =100\n",
    "for i in range(0,len(images2)):\n",
    "   # m_rgb = cv2.cvtColor(images2[i], cv2.COLOR_BGR2RGB)\n",
    "    image = np.asarray(images2[i],dtype=object)\n",
    "    new_Images.append((image,labels[i]))\n",
    "df = pd.DataFrame(new_Images, columns=['Image','Label'])\n",
    "X = np.array(df['Image'])\n",
    "y = np.array(df['Label'])\n",
    "df.head()\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "import pickle\n",
    "'''\n",
    "pickle_out = open('X.pickle', 'wb')\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open('y.pickle', 'wb')\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pickle_in = open('images.pickle', 'rb')\n",
    "images = pickle.load(pickle_in)\n",
    "pickle_in = open('labels.pickle', 'rb')\n",
    "labels = pickle.load(pickle_in)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = 0)\n",
    "#print('X_train shape:', X_train.shape) \n",
    "#print('y_train shape:', y_train.shape)\n",
    "\n",
    "#print('X_train type:', type(X_train))\n",
    "#print('y_train type:', type(y_train))\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-0841eb8775eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#X = tf.convert_to_tensor(X, np.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1037\u001b[0m       \u001b[0;31m# `Tensor` and `NumPy` input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[0;32m-> 1039\u001b[0;31m           data_adapter.train_validation_split(\n\u001b[0m\u001b[1;32m   1040\u001b[0m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m   1387\u001b[0m   \u001b[0;31m# Assumes all arrays have the same batch shape or are `None`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m   \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_non_none\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m   \u001b[0msplit_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msplit_at\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msplit_at\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'tuple'"
     ]
    }
   ],
   "source": [
    "# Convolutional Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#X = tf.convert_to_tensor(X, np.float32)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs = 3, validation_data = (X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Testing.py",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
